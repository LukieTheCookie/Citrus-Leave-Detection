{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrPE_AjGVpdq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization,AveragePooling2D,Input\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import cv2 \n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating classes without the Melanose leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Black spot', 'canker', 'greening', 'healthy'] #Creating a list of classes excluding Melanose since it should be ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Directories to Insert the Augmented and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(dirName): #Creating files to store augmented and test data\n",
    "    if not os.path.exists(os.path.join(dirName)): #As mentioned in the README, create the \"Dateset\" file and store the \"Citrus\" file in it\n",
    "        os.mkdir(dirName)\n",
    "    dirName1 = dirName+'/' \n",
    "    for folder in classes:\n",
    "        dirName1=dirName1+folder\n",
    "        if not os.path.exists(dirName1):\n",
    "            os.mkdir(dirName1)\n",
    "        dirName1 = dirName+'/'\n",
    "\n",
    "createFolder('Dataset/TestingData')\n",
    "createFolder('Dataset/AugmentedData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor_datagen = ImageDataGenerator( \n",
    "    rotation_range=45,      #Rotating image between 0-45 degree angle\n",
    "    width_shift_range=0.1,  #Flips image horizontally\n",
    "    height_shift_range=0.1, #Flipms image vertically\n",
    "    zoom_range=0.15,        #Zooms into image\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\",   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Aug=[7,7,6,19]\n",
    "def Augment(path,class_Ind):\n",
    "    \n",
    "    for img_name in os.listdir(path): #Loop through images in citrus/leaves folder\n",
    "        img = np.expand_dims(cv2.imread(os.path.join(path,img_name)),axis=0) #Takes image from the directory\n",
    "        i=num_Aug[class_Ind]\n",
    "        for batch in augmentor_datagen.flow( \n",
    "            img,\n",
    "            batch_size=1,\n",
    "            save_to_dir=os.path.join(\"Dataset/AugmentedData/\"+classes[class_Ind]), #Adds augmented data into Dataset folder\n",
    "            save_prefix=classes[class_Ind],\n",
    "            save_format='jpeg'): #Format of image\n",
    "\n",
    "            i-=1\n",
    "            if i==0:  #we generat image for each picture in batch\n",
    "                break\n",
    "\n",
    "for folder in classes:\n",
    "    path = os.path.join('Dataset/Citrus/Leaves/',folder)\n",
    "    class_Ind= classes.index(folder)\n",
    "    Augment(path,class_Ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Random data from Augmented data to Testing data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveImages(to_path,class_Ind):\n",
    "    from_dir=\"Dataset/AugmentedData/\"+classes[Ind]\n",
    "    files = os.listdir(from_dir)\n",
    "    # Select 0.2 of the files randomly \n",
    "    random_files = np.random.choice(files, int(len(files)*.2))\n",
    "\n",
    "    # moving 10 files from each class to testing data file\n",
    "    i=0\n",
    "    for x in random_files:\n",
    "        shutil.move(from_dir+'/'+x, to_path) # move file to anthore dir\n",
    "        i+=1\n",
    "        if i==20:\n",
    "            break\n",
    "\n",
    "for folder in classes:\n",
    "    path = os.path.join('Dataset/TestingData/',folder)#Adding images to dateset/testingdata folder\n",
    "    Ind= classes.index(folder)\n",
    "    moveImages(path,Ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HFLhJr7XkJGd",
    "outputId": "f30cc0a9-0302-44fe-8a23-11ffc49425f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #80%-20% split\n",
    "    validation_split=0.2, \n",
    ")\n",
    "#training data\n",
    "train_generator = training_datagen.flow_from_directory( \n",
    "    directory='Dataset/AugmentedData/', \n",
    "    target_size=(256,256), #imgae size 256x256\n",
    "    shuffle=True, \n",
    "    batch_size=64,\n",
    "    subset='training',\n",
    ")\n",
    "#validtaion data\n",
    "validation_generator = training_datagen.flow_from_directory(\n",
    "    directory='Dataset/AugmentedData/',\n",
    "    target_size=(256,256),\n",
    "    shuffle=True, \n",
    "    batch_size=64,\n",
    "    subset='validation',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jI8TRqBak8Qv",
    "outputId": "345272ca-ddb9-4902-8f01-14e205257d5f"
   },
   "outputs": [],
   "source": [
    "model = Sequential([ #Resnet model with 5 convolutional layers and 5 MaxPool layers\n",
    "    #Input Layer \n",
    "    Conv2D(32, (3,3), padding='same',activation='relu',input_shape=(256, 256, 3),),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3),activation='relu', padding='same', ),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "   \n",
    "    Conv2D(256, (3,3), activation='relu', padding='same', ),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    \n",
    "    Conv2D(512, (3,3), activation='relu', padding='same', ),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    #Connection Layer\n",
    "    Dense(512,activation='relu', activity_regularizer=regularizers.l2(1e-5)),\n",
    "    Dense(4,activation='softmax'),\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "con = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "ResNet = model.fit(train_generator, epochs=50, validation_data = validation_generator, callbacks=[con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the accuracy/epoch of Resnet Model\n",
    "plt.plot(ResNet.history['accuracy'])\n",
    "plt.plot(ResNet.history['val_accuracy'])\n",
    "plt.title('ResNet Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()\n",
    "# Plotting loss/epoch of resnet model\n",
    "plt.plot(ResNet.history['loss'])\n",
    "plt.plot(ResNet.history['val_loss'])\n",
    "plt.title('ResNet Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential([\n",
    "    \n",
    "    Conv2D(32, (3,3), padding='same',activation='relu',input_shape=(256, 256, 3),),\n",
    "    \n",
    "    Conv2D(filters=6, kernel_size=(5, 5),activation='sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=16, kernel_size=(5, 5), activation='sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(units=120, activation='sigmoid'),\n",
    "    Dense(units=84, activation='sigmoid'),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "con = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "LeNet = model.fit(train_generator, epochs=50, validation_data = validation_generator, callbacks=[con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(LeNet.history['accuracy'])\n",
    "plt.plot(LeNet.history['val_accuracy'])\n",
    "plt.title('ResNet Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(LeNet.history['loss'])\n",
    "plt.plot(LeNet.history['val_loss'])\n",
    "plt.title('ResNet Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential([\n",
    "\n",
    "    Input(shape=(256, 256, 3)),\n",
    "\n",
    "    Conv2D(filters=96, kernel_size=(11, 11),\n",
    "           strides=(4, 4), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(5, 5), \n",
    "           strides=(1, 1), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), \n",
    "           strides=(1, 1), padding='same', activation='relu'),\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), \n",
    "           strides=(1, 1), padding='same', activation='relu'),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), \n",
    "           strides=(1, 1), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(units=4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(1000, activation='softmax')\n",
    "])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "con = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "AlexNet = model.fit(train_generator, epochs=50, validation_data = validation_generator, callbacks=[con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(AlexNet.history['accuracy'])\n",
    "plt.plot(AlexNet.history['val_accuracy'])\n",
    "plt.title('ResNet Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(AlexNet.history['loss'])\n",
    "plt.plot(AlexNet.history['val_loss'])\n",
    "plt.title('ResNet Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential([  \n",
    "    Input(shape=(256,256,3)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(1000, activation='softmax')\n",
    "])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "con = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "VGG16 = model.fit(train_generator, epochs=50, validation_data = validation_generator, callbacks=[con])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Model Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(VGG16.history['accuracy'])\n",
    "plt.plot(VGG16.history['val_accuracy'])\n",
    "plt.title('ResNet Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(VGG16.history['loss'])\n",
    "plt.plot(VGG16.history['val_loss'])\n",
    "plt.title('ResNet Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale = 1./255) #Rescalling Image\n",
    "image_pred = image_gen.flow_from_directory(\"Dataset/TestingData/\" ,target_size=(256,256),batch_size=5,shuffle=False,class_mode='categorical',)\n",
    "image_pred.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(Cm, classes,title='Confusion matrix',Cmap=plt.cm.Blues):\n",
    "    plt.imshow(Cm, interpolation='nearest', Cmap=Cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "\n",
    "    thresh = Cm.max() / 2.\n",
    "    for i, j in itertools.product(range(Cm.shape[0]), range(Cm.shape[1])):\n",
    "        plt.text(j, i, Cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if Cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predictions = model.predict_generator(image_pred)\n",
    "Y_predicted_class_indices= np.argmax(Y_predictions,axis=1)\n",
    "cm=confusion_matrix(image_pred.classes, Y_predicted_class_indices)\n",
    "plot_confusion_matrix(cm, classes=classes,title='Leave Disease Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
